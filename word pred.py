# -*- coding: utf-8 -*-
"""Welcome to Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv("qoute_dataset.csv")

from tensorflow.keras.preprocessing.text import Tokenizer

quotes = df['quote']
quotes.head()

# performing some data cleaning for nlp type project

#also converting all character to lower string
quotes = quotes.str.lower()

# removing comma","" and special character
import string
translator = str.maketrans('', '', string.punctuation)
quotes = quotes.apply(lambda x: x.translate(translator))

vocab_size = 10000

tokinizer = Tokenizer(num_words=vocab_size)
tokinizer.fit_on_texts(quotes)

word_index = tokinizer.word_index
print(len(word_index))
list(word_index.items())[:10]

# tokenization + integer encoding.
sequence = tokinizer.texts_to_sequences(quotes)

X = []
y = []

for seq in sequence:
  for i in range(1,len(seq)):
    input_seq = seq[:i]
    output_seq = seq[i]
    X.append(input_seq)
    y.append(output_seq)

len(X)

len(y)

max_len = max(len(x) for x in X)
print(max_len)

# padding so that each and every sentece can have same lenght

from tensorflow.keras.preprocessing.sequence import pad_sequences
X_padded = pad_sequences(X, maxlen=max_len, padding='pre')

y = np.array(y)

X_padded.shape

# OHE performing
from tensorflow.keras.utils import to_categorical
y_one_hot = to_categorical(y, num_classes=vocab_size)

y_one_hot.shape

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding,SimpleRNN,LSTM, Dense

embedding_dim = 50
rnn_units = 128

# creating rnn model with hidden layer and output layer

rnn_model = Sequential()

rnn_model.add(
    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len)
)
rnn_model.add(SimpleRNN(units=rnn_units))
rnn_model.add(Dense(units=vocab_size, activation='softmax'))

# compile model by assigning optimizer , loss function
rnn_model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

rnn_model.summary()

# creating LSTM model


lstm_model = Sequential()
lstm_model.add(
    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len)
)
lstm_model.add(LSTM(units=rnn_units))
lstm_model.add(Dense(units=vocab_size, activation='softmax'))

# compile model by assigning optimizer , loss function
lstm_model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

lstm_model.summary()

from tensorflow.keras.models import load_model

lstm_model = load_model("lstm_model.h5")

lstm_model.save("lstm_model.h5")

index_to_word = {}
for word, index in word_index.items():
  index_to_word[index] = word

from tensorflow.keras.preprocessing.sequence import pad_sequences

# creating word prdictiorn function



def predictor(model,tokenizer,text,max_len):
  text = text.lower()

  seq = tokenizer.texts_to_sequences([text])[0]
  seq = pad_sequences([seq], maxlen=max_len, padding='pre')

  pred = model.predict(seq,verbose = 0)
  pred_index = np.argmax(pred)
  return index_to_word[pred_index]

seed_text = "what are you"
next_word = predictor(lstm_model,tokinizer,seed_text,max_len)
print(next_word)

# model that generate text

def generate_text(model,tokenizer,seed_text,max_len,n_words):
  for _ in range(n_words):
    next_word = predictor(model,tokenizer,seed_text,max_len)
    if next_word == "":
      break
    seed_text += " " + next_word
  return seed_text

seed = "are you a "
generate_text = generate_text(lstm_model,tokinizer,seed,max_len,10)
print(generate_text)

import pickle
with open("tokenizer.pkl", "wb") as f:
  pickle.dump(tokinizer, f)

with open("max_len.pkl", "wb") as f:
  pickle.dump(max_len, f)